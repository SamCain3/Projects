{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pdequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Resources/data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2339a9b08b</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16fab9f95b</td>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>like</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74a76f6e0a</td>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>DANGERously</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04dd1d2e34</td>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bbe3cbf620</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "0   cb774db0d1                I`d have responded, if I were going   \n",
       "1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7   50e14c0bb8                                         Soooo high   \n",
       "8   e050245fbd                                        Both of you   \n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
       "11  16fab9f95b  I really really like the song Love Story by Ta...   \n",
       "12  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
       "13  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n",
       "14  bbe3cbf620                         test test from the LG enV2   \n",
       "\n",
       "                                        selected_text sentiment  \n",
       "0                 I`d have responded, if I were going   neutral  \n",
       "1                                            Sooo SAD  negative  \n",
       "2                                         bullying me  negative  \n",
       "3                                      leave me alone  negative  \n",
       "4                                       Sons of ****,  negative  \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                 fun  positive  \n",
       "7                                          Soooo high   neutral  \n",
       "8                                         Both of you   neutral  \n",
       "9                        Wow... u just became cooler.  positive  \n",
       "10  as much as i love to be hopeful, i reckon the ...   neutral  \n",
       "11                                               like  positive  \n",
       "12                                        DANGERously  negative  \n",
       "13                                               lost  negative  \n",
       "14                         test test from the LG enV2   neutral  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>7781</td>\n",
       "      <td>5861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11118</td>\n",
       "      <td>11117</td>\n",
       "      <td>11111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>8582</td>\n",
       "      <td>5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID   text  selected_text\n",
       "sentiment                              \n",
       "negative     7781   7781           5861\n",
       "neutral     11118  11117          11111\n",
       "positive     8582   8582           5537"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('sentiment').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         selected_text sentiment\n",
       "0  I`d have responded, if I were going   neutral\n",
       "1                             Sooo SAD  negative\n",
       "2                          bullying me  negative\n",
       "3                       leave me alone  negative\n",
       "4                        Sons of ****,  negative"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['selected_text','sentiment']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"selected_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"selected_text\"].fillna(\"No content\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I`d have responded, if I were going',\n",
       " 'Sooo SAD',\n",
       " 'bullying me',\n",
       " 'leave me alone',\n",
       " 'Sons of ****,']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "data_to_list = train['selected_text'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['have', 'responded', 'if', 'were', 'going'], ['sooo', 'sad'], ['bullying', 'me'], ['leave', 'me', 'alone'], ['sons', 'of'], ['some', 'shameless', 'plugging', 'for', 'the', 'best', 'rangers', 'forum', 'on', 'earth'], ['fun'], ['soooo', 'high'], ['both', 'of', 'you'], ['wow', 'just', 'became', 'cooler']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have responded if were going', 'sooo sad', 'bullying me', 'leave me alone', 'sons of']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['sentiment'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   68  146   41]\n",
      " [   0    0    0 ...    0  397   65]\n",
      " [   0    0    0 ...    0    0   11]\n",
      " ...\n",
      " [   0    0    0 ...  372   10    3]\n",
      " [   0    0    0 ...   24  542    4]\n",
      " [   0    0    0 ... 2424  199  657]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20610 6871 20610 6871\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/5\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.8081 - accuracy: 0.6591\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74152, saving model to best_model0.hdf5\n",
      "645/645 [==============================] - 18s 27ms/step - loss: 0.8079 - accuracy: 0.6592 - val_loss: 0.6660 - val_accuracy: 0.7415\n",
      "Epoch 2/5\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.7832\n",
      "Epoch 2: val_accuracy improved from 0.74152 to 0.77296, saving model to best_model0.hdf5\n",
      "645/645 [==============================] - 17s 26ms/step - loss: 0.5784 - accuracy: 0.7832 - val_loss: 0.5735 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.8109\n",
      "Epoch 3: val_accuracy improved from 0.77296 to 0.80076, saving model to best_model0.hdf5\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.4937 - accuracy: 0.8109 - val_loss: 0.5139 - val_accuracy: 0.8008\n",
      "Epoch 4/5\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.8234\n",
      "Epoch 4: val_accuracy improved from 0.80076 to 0.81051, saving model to best_model0.hdf5\n",
      "645/645 [==============================] - 17s 26ms/step - loss: 0.4677 - accuracy: 0.8236 - val_loss: 0.4881 - val_accuracy: 0.8105\n",
      "Epoch 5/5\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.8283\n",
      "Epoch 5: val_accuracy did not improve from 0.81051\n",
      "645/645 [==============================] - 17s 26ms/step - loss: 0.4629 - accuracy: 0.8282 - val_loss: 0.5302 - val_accuracy: 0.7954\n"
     ]
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(layers.Embedding(max_words, 15))\n",
    "model0.add(layers.SimpleRNN(15))\n",
    "model0.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model0.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint0 = ModelCheckpoint(\"best_model0.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model0.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test),callbacks=[checkpoint0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.8310 - accuracy: 0.6353\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70616, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 31s 45ms/step - loss: 0.8310 - accuracy: 0.6353 - val_loss: 0.6825 - val_accuracy: 0.7062\n",
      "Epoch 2/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5938 - accuracy: 0.7653\n",
      "Epoch 2: val_accuracy improved from 0.70616 to 0.79130, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.5937 - accuracy: 0.7654 - val_loss: 0.5353 - val_accuracy: 0.7913\n",
      "Epoch 3/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8010\n",
      "Epoch 3: val_accuracy improved from 0.79130 to 0.80643, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 31s 49ms/step - loss: 0.5107 - accuracy: 0.8010 - val_loss: 0.4948 - val_accuracy: 0.8064\n",
      "Epoch 4/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8159\n",
      "Epoch 4: val_accuracy improved from 0.80643 to 0.81633, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4764 - accuracy: 0.8159 - val_loss: 0.4798 - val_accuracy: 0.8163\n",
      "Epoch 5/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4553 - accuracy: 0.8257\n",
      "Epoch 5: val_accuracy improved from 0.81633 to 0.82230, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.4553 - accuracy: 0.8257 - val_loss: 0.4668 - val_accuracy: 0.8223\n",
      "Epoch 6/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8313\n",
      "Epoch 6: val_accuracy improved from 0.82230 to 0.82492, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.4379 - accuracy: 0.8313 - val_loss: 0.4613 - val_accuracy: 0.8249\n",
      "Epoch 7/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.8408\n",
      "Epoch 7: val_accuracy improved from 0.82492 to 0.82695, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.4253 - accuracy: 0.8408 - val_loss: 0.4618 - val_accuracy: 0.8270\n",
      "Epoch 8/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8450\n",
      "Epoch 8: val_accuracy improved from 0.82695 to 0.83161, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.4144 - accuracy: 0.8450 - val_loss: 0.4489 - val_accuracy: 0.8316\n",
      "Epoch 9/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8449\n",
      "Epoch 9: val_accuracy improved from 0.83161 to 0.83263, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.4102 - accuracy: 0.8449 - val_loss: 0.4487 - val_accuracy: 0.8326\n",
      "Epoch 10/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8477\n",
      "Epoch 10: val_accuracy did not improve from 0.83263\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.4046 - accuracy: 0.8476 - val_loss: 0.4528 - val_accuracy: 0.8236\n",
      "Epoch 11/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8523\n",
      "Epoch 11: val_accuracy improved from 0.83263 to 0.83292, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 46ms/step - loss: 0.3965 - accuracy: 0.8523 - val_loss: 0.4416 - val_accuracy: 0.8329\n",
      "Epoch 12/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.8531\n",
      "Epoch 12: val_accuracy improved from 0.83292 to 0.83365, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3932 - accuracy: 0.8531 - val_loss: 0.4347 - val_accuracy: 0.8336\n",
      "Epoch 13/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8546\n",
      "Epoch 13: val_accuracy improved from 0.83365 to 0.83423, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3863 - accuracy: 0.8546 - val_loss: 0.4357 - val_accuracy: 0.8342\n",
      "Epoch 14/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8588\n",
      "Epoch 14: val_accuracy improved from 0.83423 to 0.83569, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3829 - accuracy: 0.8588 - val_loss: 0.4342 - val_accuracy: 0.8357\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8606\n",
      "Epoch 15: val_accuracy did not improve from 0.83569\n",
      "645/645 [==============================] - 29s 46ms/step - loss: 0.3766 - accuracy: 0.8606 - val_loss: 0.4371 - val_accuracy: 0.8336\n",
      "Epoch 16/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8625\n",
      "Epoch 16: val_accuracy improved from 0.83569 to 0.83758, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3703 - accuracy: 0.8625 - val_loss: 0.4355 - val_accuracy: 0.8376\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.8623\n",
      "Epoch 17: val_accuracy improved from 0.83758 to 0.83860, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3697 - accuracy: 0.8623 - val_loss: 0.4313 - val_accuracy: 0.8386\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.8641\n",
      "Epoch 18: val_accuracy did not improve from 0.83860\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3683 - accuracy: 0.8641 - val_loss: 0.4344 - val_accuracy: 0.8354\n",
      "Epoch 19/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.8636\n",
      "Epoch 19: val_accuracy did not improve from 0.83860\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3622 - accuracy: 0.8636 - val_loss: 0.4334 - val_accuracy: 0.8386\n",
      "Epoch 20/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.8655\n",
      "Epoch 20: val_accuracy did not improve from 0.83860\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3600 - accuracy: 0.8655 - val_loss: 0.4293 - val_accuracy: 0.8385\n",
      "Epoch 21/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8675\n",
      "Epoch 21: val_accuracy improved from 0.83860 to 0.84224, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.3585 - accuracy: 0.8675 - val_loss: 0.4318 - val_accuracy: 0.8422\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8673\n",
      "Epoch 22: val_accuracy did not improve from 0.84224\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.3551 - accuracy: 0.8673 - val_loss: 0.4257 - val_accuracy: 0.8409\n",
      "Epoch 23/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3536 - accuracy: 0.8684\n",
      "Epoch 23: val_accuracy improved from 0.84224 to 0.84413, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3536 - accuracy: 0.8685 - val_loss: 0.4272 - val_accuracy: 0.8441\n",
      "Epoch 24/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8715\n",
      "Epoch 24: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.3518 - accuracy: 0.8715 - val_loss: 0.4313 - val_accuracy: 0.8428\n",
      "Epoch 25/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8706\n",
      "Epoch 25: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.3497 - accuracy: 0.8706 - val_loss: 0.4321 - val_accuracy: 0.8402\n",
      "Epoch 26/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3484 - accuracy: 0.8693\n",
      "Epoch 26: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3484 - accuracy: 0.8692 - val_loss: 0.4277 - val_accuracy: 0.8401\n",
      "Epoch 27/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.8694\n",
      "Epoch 27: val_accuracy did not improve from 0.84413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3499 - accuracy: 0.8694 - val_loss: 0.4248 - val_accuracy: 0.8435\n",
      "Epoch 28/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.8702\n",
      "Epoch 28: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 27s 41ms/step - loss: 0.3459 - accuracy: 0.8702 - val_loss: 0.4283 - val_accuracy: 0.8325\n",
      "Epoch 29/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8720\n",
      "Epoch 29: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3442 - accuracy: 0.8720 - val_loss: 0.4253 - val_accuracy: 0.8401\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8736\n",
      "Epoch 30: val_accuracy did not improve from 0.84413\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3438 - accuracy: 0.8736 - val_loss: 0.4320 - val_accuracy: 0.8414\n",
      "Epoch 31/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.8743\n",
      "Epoch 31: val_accuracy improved from 0.84413 to 0.84471, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3411 - accuracy: 0.8743 - val_loss: 0.4311 - val_accuracy: 0.8447\n",
      "Epoch 32/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8749\n",
      "Epoch 32: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3425 - accuracy: 0.8749 - val_loss: 0.4264 - val_accuracy: 0.8440\n",
      "Epoch 33/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.8755\n",
      "Epoch 33: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3400 - accuracy: 0.8755 - val_loss: 0.4205 - val_accuracy: 0.8431\n",
      "Epoch 34/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8757\n",
      "Epoch 34: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 46ms/step - loss: 0.3389 - accuracy: 0.8757 - val_loss: 0.4253 - val_accuracy: 0.8437\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8766\n",
      "Epoch 35: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3408 - accuracy: 0.8766 - val_loss: 0.4243 - val_accuracy: 0.8435\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.8755\n",
      "Epoch 36: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3374 - accuracy: 0.8755 - val_loss: 0.4279 - val_accuracy: 0.8440\n",
      "Epoch 37/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8767\n",
      "Epoch 37: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 28s 43ms/step - loss: 0.3372 - accuracy: 0.8767 - val_loss: 0.4273 - val_accuracy: 0.8425\n",
      "Epoch 38/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.8759\n",
      "Epoch 38: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.3376 - accuracy: 0.8759 - val_loss: 0.4256 - val_accuracy: 0.8437\n",
      "Epoch 39/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8760\n",
      "Epoch 39: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.3370 - accuracy: 0.8760 - val_loss: 0.4284 - val_accuracy: 0.8418\n",
      "Epoch 40/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8776\n",
      "Epoch 40: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.3349 - accuracy: 0.8776 - val_loss: 0.4316 - val_accuracy: 0.8412\n",
      "Epoch 41/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.8770\n",
      "Epoch 41: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3320 - accuracy: 0.8770 - val_loss: 0.4304 - val_accuracy: 0.8419\n",
      "Epoch 42/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8807\n",
      "Epoch 42: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 44ms/step - loss: 0.3307 - accuracy: 0.8806 - val_loss: 0.4301 - val_accuracy: 0.8430\n",
      "Epoch 43/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.8763\n",
      "Epoch 43: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3366 - accuracy: 0.8763 - val_loss: 0.4306 - val_accuracy: 0.8443\n",
      "Epoch 44/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8774\n",
      "Epoch 44: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 41ms/step - loss: 0.3327 - accuracy: 0.8774 - val_loss: 0.4304 - val_accuracy: 0.8430\n",
      "Epoch 45/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8773\n",
      "Epoch 45: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 41ms/step - loss: 0.3311 - accuracy: 0.8773 - val_loss: 0.4309 - val_accuracy: 0.8431\n",
      "Epoch 46/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.8793\n",
      "Epoch 46: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 41ms/step - loss: 0.3280 - accuracy: 0.8793 - val_loss: 0.4322 - val_accuracy: 0.8428\n",
      "Epoch 47/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3323 - accuracy: 0.8767\n",
      "Epoch 47: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3324 - accuracy: 0.8767 - val_loss: 0.4286 - val_accuracy: 0.8430\n",
      "Epoch 48/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8798\n",
      "Epoch 48: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3290 - accuracy: 0.8798 - val_loss: 0.4292 - val_accuracy: 0.8412\n",
      "Epoch 49/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.8798\n",
      "Epoch 49: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 42ms/step - loss: 0.3288 - accuracy: 0.8798 - val_loss: 0.4348 - val_accuracy: 0.8421\n",
      "Epoch 50/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8769\n",
      "Epoch 50: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 28s 44ms/step - loss: 0.3264 - accuracy: 0.8769 - val_loss: 0.4379 - val_accuracy: 0.8347\n",
      "Epoch 51/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8795\n",
      "Epoch 51: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3257 - accuracy: 0.8795 - val_loss: 0.4289 - val_accuracy: 0.8417\n",
      "Epoch 52/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.8810\n",
      "Epoch 52: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3261 - accuracy: 0.8810 - val_loss: 0.4378 - val_accuracy: 0.8383\n",
      "Epoch 53/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8790\n",
      "Epoch 53: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3254 - accuracy: 0.8789 - val_loss: 0.4400 - val_accuracy: 0.8320\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.8804\n",
      "Epoch 54: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3260 - accuracy: 0.8804 - val_loss: 0.4345 - val_accuracy: 0.8435\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8815\n",
      "Epoch 55: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.3228 - accuracy: 0.8815 - val_loss: 0.4306 - val_accuracy: 0.8406\n",
      "Epoch 56/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8821\n",
      "Epoch 56: val_accuracy did not improve from 0.84471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3224 - accuracy: 0.8821 - val_loss: 0.4263 - val_accuracy: 0.8434\n",
      "Epoch 57/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8801\n",
      "Epoch 57: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.3210 - accuracy: 0.8801 - val_loss: 0.4409 - val_accuracy: 0.8380\n",
      "Epoch 58/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8800\n",
      "Epoch 58: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.3240 - accuracy: 0.8800 - val_loss: 0.4316 - val_accuracy: 0.8428\n",
      "Epoch 59/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8828\n",
      "Epoch 59: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 31s 49ms/step - loss: 0.3181 - accuracy: 0.8828 - val_loss: 0.4334 - val_accuracy: 0.8447\n",
      "Epoch 60/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.8823\n",
      "Epoch 60: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.3200 - accuracy: 0.8823 - val_loss: 0.4311 - val_accuracy: 0.8430\n",
      "Epoch 61/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3188 - accuracy: 0.8836\n",
      "Epoch 61: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 45ms/step - loss: 0.3189 - accuracy: 0.8836 - val_loss: 0.4339 - val_accuracy: 0.8398\n",
      "Epoch 62/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.8817\n",
      "Epoch 62: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 41ms/step - loss: 0.3204 - accuracy: 0.8818 - val_loss: 0.4296 - val_accuracy: 0.8422\n",
      "Epoch 63/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.8832\n",
      "Epoch 63: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 27s 43ms/step - loss: 0.3169 - accuracy: 0.8832 - val_loss: 0.4310 - val_accuracy: 0.8430\n",
      "Epoch 64/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8841\n",
      "Epoch 64: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 29s 46ms/step - loss: 0.3157 - accuracy: 0.8841 - val_loss: 0.4314 - val_accuracy: 0.8409\n",
      "Epoch 65/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8802\n",
      "Epoch 65: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 32s 49ms/step - loss: 0.3212 - accuracy: 0.8802 - val_loss: 0.4358 - val_accuracy: 0.8379\n",
      "Epoch 66/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8836\n",
      "Epoch 66: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 32s 50ms/step - loss: 0.3167 - accuracy: 0.8836 - val_loss: 0.4323 - val_accuracy: 0.8408\n",
      "Epoch 67/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3148 - accuracy: 0.8851\n",
      "Epoch 67: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 32s 49ms/step - loss: 0.3148 - accuracy: 0.8851 - val_loss: 0.4371 - val_accuracy: 0.8409\n",
      "Epoch 68/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8846\n",
      "Epoch 68: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 32s 50ms/step - loss: 0.3130 - accuracy: 0.8846 - val_loss: 0.4333 - val_accuracy: 0.8431\n",
      "Epoch 69/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8839\n",
      "Epoch 69: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 32s 50ms/step - loss: 0.3123 - accuracy: 0.8839 - val_loss: 0.4396 - val_accuracy: 0.8401\n",
      "Epoch 70/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.8842\n",
      "Epoch 70: val_accuracy did not improve from 0.84471\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.3154 - accuracy: 0.8842 - val_loss: 0.4304 - val_accuracy: 0.8437\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.8045 - accuracy: 0.6374\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70252, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 44s 64ms/step - loss: 0.8044 - accuracy: 0.6374 - val_loss: 0.6852 - val_accuracy: 0.7025\n",
      "Epoch 2/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.7674\n",
      "Epoch 2: val_accuracy improved from 0.70252 to 0.79042, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 40s 61ms/step - loss: 0.5798 - accuracy: 0.7673 - val_loss: 0.5330 - val_accuracy: 0.7904\n",
      "Epoch 3/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5036 - accuracy: 0.8039\n",
      "Epoch 3: val_accuracy improved from 0.79042 to 0.79173, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5035 - accuracy: 0.8039 - val_loss: 0.5146 - val_accuracy: 0.7917\n",
      "Epoch 4/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.8191\n",
      "Epoch 4: val_accuracy improved from 0.79173 to 0.80338, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.4696 - accuracy: 0.8191 - val_loss: 0.4872 - val_accuracy: 0.8034\n",
      "Epoch 5/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8306\n",
      "Epoch 5: val_accuracy improved from 0.80338 to 0.81808, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 58ms/step - loss: 0.4490 - accuracy: 0.8306 - val_loss: 0.4653 - val_accuracy: 0.8181\n",
      "Epoch 6/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8345\n",
      "Epoch 6: val_accuracy improved from 0.81808 to 0.82390, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.4346 - accuracy: 0.8345 - val_loss: 0.4559 - val_accuracy: 0.8239\n",
      "Epoch 7/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.8398\n",
      "Epoch 7: val_accuracy improved from 0.82390 to 0.82754, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.4220 - accuracy: 0.8398 - val_loss: 0.4480 - val_accuracy: 0.8275\n",
      "Epoch 8/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4089 - accuracy: 0.8472\n",
      "Epoch 8: val_accuracy improved from 0.82754 to 0.83088, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.4089 - accuracy: 0.8473 - val_loss: 0.4470 - val_accuracy: 0.8309\n",
      "Epoch 9/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4025 - accuracy: 0.8479\n",
      "Epoch 9: val_accuracy improved from 0.83088 to 0.83161, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.4025 - accuracy: 0.8479 - val_loss: 0.4404 - val_accuracy: 0.8316\n",
      "Epoch 10/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3943 - accuracy: 0.8511\n",
      "Epoch 10: val_accuracy did not improve from 0.83161\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.3943 - accuracy: 0.8511 - val_loss: 0.4441 - val_accuracy: 0.8299\n",
      "Epoch 11/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8547\n",
      "Epoch 11: val_accuracy did not improve from 0.83161\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.3893 - accuracy: 0.8547 - val_loss: 0.4359 - val_accuracy: 0.8316\n",
      "Epoch 12/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8579\n",
      "Epoch 12: val_accuracy improved from 0.83161 to 0.83452, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 36s 57ms/step - loss: 0.3837 - accuracy: 0.8579 - val_loss: 0.4326 - val_accuracy: 0.8345\n",
      "Epoch 13/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8586\n",
      "Epoch 13: val_accuracy improved from 0.83452 to 0.83481, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.3764 - accuracy: 0.8586 - val_loss: 0.4281 - val_accuracy: 0.8348\n",
      "Epoch 14/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3707 - accuracy: 0.8619\n",
      "Epoch 14: val_accuracy improved from 0.83481 to 0.83641, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.3708 - accuracy: 0.8619 - val_loss: 0.4319 - val_accuracy: 0.8364\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8661\n",
      "Epoch 15: val_accuracy did not improve from 0.83641\n",
      "645/645 [==============================] - 34s 52ms/step - loss: 0.3653 - accuracy: 0.8661 - val_loss: 0.4284 - val_accuracy: 0.8352\n",
      "Epoch 16/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3659 - accuracy: 0.8631\n",
      "Epoch 16: val_accuracy improved from 0.83641 to 0.83845, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.3659 - accuracy: 0.8631 - val_loss: 0.4311 - val_accuracy: 0.8385\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.8661\n",
      "Epoch 17: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.3639 - accuracy: 0.8661 - val_loss: 0.4226 - val_accuracy: 0.8380\n",
      "Epoch 18/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.8672\n",
      "Epoch 18: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.3588 - accuracy: 0.8672 - val_loss: 0.4233 - val_accuracy: 0.8376\n",
      "Epoch 19/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3552 - accuracy: 0.8695\n",
      "Epoch 19: val_accuracy improved from 0.83845 to 0.84020, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.3552 - accuracy: 0.8695 - val_loss: 0.4240 - val_accuracy: 0.8402\n",
      "Epoch 20/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8701\n",
      "Epoch 20: val_accuracy did not improve from 0.84020\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3514 - accuracy: 0.8702 - val_loss: 0.4319 - val_accuracy: 0.8382\n",
      "Epoch 21/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8723\n",
      "Epoch 21: val_accuracy did not improve from 0.84020\n",
      "645/645 [==============================] - 37s 58ms/step - loss: 0.3474 - accuracy: 0.8723 - val_loss: 0.4286 - val_accuracy: 0.8383\n",
      "Epoch 22/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.8728\n",
      "Epoch 22: val_accuracy did not improve from 0.84020\n",
      "645/645 [==============================] - 37s 58ms/step - loss: 0.3476 - accuracy: 0.8728 - val_loss: 0.4260 - val_accuracy: 0.8399\n",
      "Epoch 23/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8734\n",
      "Epoch 23: val_accuracy improved from 0.84020 to 0.84063, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3440 - accuracy: 0.8734 - val_loss: 0.4256 - val_accuracy: 0.8406\n",
      "Epoch 24/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8745\n",
      "Epoch 24: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 37s 58ms/step - loss: 0.3429 - accuracy: 0.8745 - val_loss: 0.4294 - val_accuracy: 0.8385\n",
      "Epoch 25/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3453 - accuracy: 0.8705\n",
      "Epoch 25: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3453 - accuracy: 0.8705 - val_loss: 0.4247 - val_accuracy: 0.8402\n",
      "Epoch 26/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.8737\n",
      "Epoch 26: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3412 - accuracy: 0.8738 - val_loss: 0.4264 - val_accuracy: 0.8393\n",
      "Epoch 27/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.8765\n",
      "Epoch 27: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.3349 - accuracy: 0.8765 - val_loss: 0.4369 - val_accuracy: 0.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3399 - accuracy: 0.8749\n",
      "Epoch 28: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.3398 - accuracy: 0.8749 - val_loss: 0.4315 - val_accuracy: 0.8401\n",
      "Epoch 29/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3334 - accuracy: 0.8774\n",
      "Epoch 29: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3333 - accuracy: 0.8774 - val_loss: 0.4337 - val_accuracy: 0.8405\n",
      "Epoch 30/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8795\n",
      "Epoch 30: val_accuracy improved from 0.84063 to 0.84224, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 35s 53ms/step - loss: 0.3294 - accuracy: 0.8795 - val_loss: 0.4267 - val_accuracy: 0.8422\n",
      "Epoch 31/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.8782\n",
      "Epoch 31: val_accuracy improved from 0.84224 to 0.84486, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3312 - accuracy: 0.8782 - val_loss: 0.4266 - val_accuracy: 0.8449\n",
      "Epoch 32/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8775\n",
      "Epoch 32: val_accuracy improved from 0.84486 to 0.84544, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3338 - accuracy: 0.8775 - val_loss: 0.4218 - val_accuracy: 0.8454\n",
      "Epoch 33/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3291 - accuracy: 0.8779\n",
      "Epoch 33: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3291 - accuracy: 0.8779 - val_loss: 0.4269 - val_accuracy: 0.8427\n",
      "Epoch 34/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8821\n",
      "Epoch 34: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3239 - accuracy: 0.8821 - val_loss: 0.4309 - val_accuracy: 0.8425\n",
      "Epoch 35/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8803\n",
      "Epoch 35: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3255 - accuracy: 0.8803 - val_loss: 0.4310 - val_accuracy: 0.8398\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8819\n",
      "Epoch 36: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3237 - accuracy: 0.8819 - val_loss: 0.4274 - val_accuracy: 0.8422\n",
      "Epoch 37/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.8854\n",
      "Epoch 37: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3177 - accuracy: 0.8854 - val_loss: 0.4354 - val_accuracy: 0.8414\n",
      "Epoch 38/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.8808\n",
      "Epoch 38: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3225 - accuracy: 0.8808 - val_loss: 0.4327 - val_accuracy: 0.8424\n",
      "Epoch 39/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3175 - accuracy: 0.8846\n",
      "Epoch 39: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 35s 54ms/step - loss: 0.3175 - accuracy: 0.8846 - val_loss: 0.4275 - val_accuracy: 0.8411\n",
      "Epoch 40/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.8828\n",
      "Epoch 40: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 36s 55ms/step - loss: 0.3200 - accuracy: 0.8828 - val_loss: 0.4324 - val_accuracy: 0.8421\n",
      "Epoch 41/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3162 - accuracy: 0.8859\n",
      "Epoch 41: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 38s 58ms/step - loss: 0.3162 - accuracy: 0.8859 - val_loss: 0.4294 - val_accuracy: 0.8451\n",
      "Epoch 42/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8852\n",
      "Epoch 42: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 38s 58ms/step - loss: 0.3147 - accuracy: 0.8852 - val_loss: 0.4410 - val_accuracy: 0.8441\n",
      "Epoch 43/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3128 - accuracy: 0.8872\n",
      "Epoch 43: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3128 - accuracy: 0.8871 - val_loss: 0.4419 - val_accuracy: 0.8440\n",
      "Epoch 44/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8853\n",
      "Epoch 44: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3137 - accuracy: 0.8853 - val_loss: 0.4288 - val_accuracy: 0.8446\n",
      "Epoch 45/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8850\n",
      "Epoch 45: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3106 - accuracy: 0.8851 - val_loss: 0.4333 - val_accuracy: 0.8446\n",
      "Epoch 46/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8862\n",
      "Epoch 46: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.3110 - accuracy: 0.8862 - val_loss: 0.4361 - val_accuracy: 0.8408\n",
      "Epoch 47/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8852\n",
      "Epoch 47: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3108 - accuracy: 0.8852 - val_loss: 0.4410 - val_accuracy: 0.8424\n",
      "Epoch 48/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.8898\n",
      "Epoch 48: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3083 - accuracy: 0.8898 - val_loss: 0.4420 - val_accuracy: 0.8425\n",
      "Epoch 49/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.8877\n",
      "Epoch 49: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3087 - accuracy: 0.8877 - val_loss: 0.4340 - val_accuracy: 0.8428\n",
      "Epoch 50/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8889\n",
      "Epoch 50: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3046 - accuracy: 0.8889 - val_loss: 0.4345 - val_accuracy: 0.8454\n",
      "Epoch 51/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8901\n",
      "Epoch 51: val_accuracy did not improve from 0.84544\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3024 - accuracy: 0.8901 - val_loss: 0.4369 - val_accuracy: 0.8443\n",
      "Epoch 52/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8888\n",
      "Epoch 52: val_accuracy improved from 0.84544 to 0.84602, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3043 - accuracy: 0.8888 - val_loss: 0.4366 - val_accuracy: 0.8460\n",
      "Epoch 53/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.8898\n",
      "Epoch 53: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3038 - accuracy: 0.8898 - val_loss: 0.4411 - val_accuracy: 0.8433\n",
      "Epoch 54/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3067 - accuracy: 0.8873\n",
      "Epoch 54: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3067 - accuracy: 0.8873 - val_loss: 0.4395 - val_accuracy: 0.8427\n",
      "Epoch 55/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8904\n",
      "Epoch 55: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3041 - accuracy: 0.8904 - val_loss: 0.4457 - val_accuracy: 0.8382\n",
      "Epoch 56/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3034 - accuracy: 0.8894\n",
      "Epoch 56: val_accuracy did not improve from 0.84602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 39s 60ms/step - loss: 0.3034 - accuracy: 0.8894 - val_loss: 0.4406 - val_accuracy: 0.8415\n",
      "Epoch 57/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8917\n",
      "Epoch 57: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.2988 - accuracy: 0.8917 - val_loss: 0.4456 - val_accuracy: 0.8415\n",
      "Epoch 58/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.8898\n",
      "Epoch 58: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.3013 - accuracy: 0.8898 - val_loss: 0.4435 - val_accuracy: 0.8421\n",
      "Epoch 59/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8913\n",
      "Epoch 59: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.3006 - accuracy: 0.8913 - val_loss: 0.4439 - val_accuracy: 0.8414\n",
      "Epoch 60/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8912\n",
      "Epoch 60: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.2998 - accuracy: 0.8912 - val_loss: 0.4403 - val_accuracy: 0.8433\n",
      "Epoch 61/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8918\n",
      "Epoch 61: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.2966 - accuracy: 0.8918 - val_loss: 0.4434 - val_accuracy: 0.8403\n",
      "Epoch 62/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.8919\n",
      "Epoch 62: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.2969 - accuracy: 0.8919 - val_loss: 0.4431 - val_accuracy: 0.8449\n",
      "Epoch 63/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.8926\n",
      "Epoch 63: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 36s 56ms/step - loss: 0.2964 - accuracy: 0.8926 - val_loss: 0.4447 - val_accuracy: 0.8415\n",
      "Epoch 64/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.8920\n",
      "Epoch 64: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 37s 57ms/step - loss: 0.2947 - accuracy: 0.8920 - val_loss: 0.4530 - val_accuracy: 0.8402\n",
      "Epoch 65/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2954 - accuracy: 0.8944\n",
      "Epoch 65: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 40s 61ms/step - loss: 0.2954 - accuracy: 0.8944 - val_loss: 0.4487 - val_accuracy: 0.8414\n",
      "Epoch 66/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8913\n",
      "Epoch 66: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.2993 - accuracy: 0.8912 - val_loss: 0.4423 - val_accuracy: 0.8450\n",
      "Epoch 67/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8927\n",
      "Epoch 67: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.2953 - accuracy: 0.8927 - val_loss: 0.4442 - val_accuracy: 0.8395\n",
      "Epoch 68/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8949\n",
      "Epoch 68: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.2908 - accuracy: 0.8950 - val_loss: 0.4525 - val_accuracy: 0.8447\n",
      "Epoch 69/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8928\n",
      "Epoch 69: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.2956 - accuracy: 0.8928 - val_loss: 0.4482 - val_accuracy: 0.8433\n",
      "Epoch 70/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2906 - accuracy: 0.8933\n",
      "Epoch 70: val_accuracy did not improve from 0.84602\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.2905 - accuracy: 0.8933 - val_loss: 0.4471 - val_accuracy: 0.8403\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 1.0324 - acc: 0.5635WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 6s 8ms/step - loss: 1.0297 - acc: 0.5647 - val_loss: 0.9005 - val_acc: 0.6105\n",
      "Epoch 2/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.8558 - acc: 0.6208WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.8559 - acc: 0.6208 - val_loss: 0.8302 - val_acc: 0.6303\n",
      "Epoch 3/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.7598 - acc: 0.7157WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.7598 - acc: 0.7157 - val_loss: 0.7338 - val_acc: 0.7507\n",
      "Epoch 4/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.6762 - acc: 0.7741WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.6757 - acc: 0.7746 - val_loss: 0.6911 - val_acc: 0.7690\n",
      "Epoch 5/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.6357 - acc: 0.7854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.6356 - acc: 0.7853 - val_loss: 0.6569 - val_acc: 0.7705\n",
      "Epoch 6/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.6102 - acc: 0.7915WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.6100 - acc: 0.7916 - val_loss: 0.6500 - val_acc: 0.7650\n",
      "Epoch 7/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.5907 - acc: 0.7985WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.5907 - acc: 0.7984 - val_loss: 0.6705 - val_acc: 0.7711\n",
      "Epoch 8/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.8048WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.5745 - acc: 0.8048 - val_loss: 0.6250 - val_acc: 0.7801\n",
      "Epoch 9/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.5545 - acc: 0.8157WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.5556 - acc: 0.8153 - val_loss: 0.6077 - val_acc: 0.7875\n",
      "Epoch 10/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.8298WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.5216 - acc: 0.8298 - val_loss: 0.5859 - val_acc: 0.8088\n",
      "Epoch 11/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.4905 - acc: 0.8438WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4902 - acc: 0.8440 - val_loss: 0.5540 - val_acc: 0.8140\n",
      "Epoch 12/70\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8503WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4718 - acc: 0.8506 - val_loss: 0.5591 - val_acc: 0.8185\n",
      "Epoch 13/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8561WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4587 - acc: 0.8564 - val_loss: 0.5492 - val_acc: 0.8219\n",
      "Epoch 14/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8602WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4499 - acc: 0.8602 - val_loss: 0.5261 - val_acc: 0.8258\n",
      "Epoch 15/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8631WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 6s 9ms/step - loss: 0.4417 - acc: 0.8631 - val_loss: 0.5448 - val_acc: 0.8137\n",
      "Epoch 16/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.4354 - acc: 0.8656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4359 - acc: 0.8654 - val_loss: 0.5891 - val_acc: 0.7868\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4299 - acc: 0.8678WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4299 - acc: 0.8678 - val_loss: 0.5169 - val_acc: 0.8270\n",
      "Epoch 18/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.4260 - acc: 0.8697WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4258 - acc: 0.8697 - val_loss: 0.5207 - val_acc: 0.8243\n",
      "Epoch 19/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8707WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4211 - acc: 0.8702 - val_loss: 0.5252 - val_acc: 0.8207\n",
      "Epoch 20/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8724WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4171 - acc: 0.8724 - val_loss: 0.5179 - val_acc: 0.8318\n",
      "Epoch 21/70\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8724WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4137 - acc: 0.8723 - val_loss: 0.5058 - val_acc: 0.8328\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4095 - acc: 0.8762WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4095 - acc: 0.8762 - val_loss: 0.5149 - val_acc: 0.8319\n",
      "Epoch 23/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4064 - acc: 0.8758WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4064 - acc: 0.8758 - val_loss: 0.5056 - val_acc: 0.8280\n",
      "Epoch 24/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.4026 - acc: 0.8786WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 6s 9ms/step - loss: 0.4030 - acc: 0.8784 - val_loss: 0.5349 - val_acc: 0.8312\n",
      "Epoch 25/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.8791WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.4001 - acc: 0.8791 - val_loss: 0.5093 - val_acc: 0.8288\n",
      "Epoch 26/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3968 - acc: 0.8792 - val_loss: 0.5116 - val_acc: 0.8351\n",
      "Epoch 27/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3930 - acc: 0.8821WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3930 - acc: 0.8821 - val_loss: 0.5188 - val_acc: 0.8319\n",
      "Epoch 28/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8822WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3923 - acc: 0.8820 - val_loss: 0.5699 - val_acc: 0.7983\n",
      "Epoch 29/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8842WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3879 - acc: 0.8839 - val_loss: 0.5290 - val_acc: 0.8345\n",
      "Epoch 30/70\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8850WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3859 - acc: 0.8851 - val_loss: 0.5110 - val_acc: 0.8284\n",
      "Epoch 31/70\n",
      "636/645 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8839WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3837 - acc: 0.8845 - val_loss: 0.5232 - val_acc: 0.8208\n",
      "Epoch 32/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.3803 - acc: 0.8854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3806 - acc: 0.8852 - val_loss: 0.5189 - val_acc: 0.8272\n",
      "Epoch 33/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3791 - acc: 0.8866WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3787 - acc: 0.8870 - val_loss: 0.5556 - val_acc: 0.8312\n",
      "Epoch 34/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8882WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3753 - acc: 0.8881 - val_loss: 0.5293 - val_acc: 0.8187\n",
      "Epoch 35/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.8889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3743 - acc: 0.8887 - val_loss: 0.5315 - val_acc: 0.8299\n",
      "Epoch 36/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3717 - acc: 0.8881WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3717 - acc: 0.8881 - val_loss: 0.5172 - val_acc: 0.8328\n",
      "Epoch 37/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8902WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3701 - acc: 0.8903 - val_loss: 0.5149 - val_acc: 0.8288\n",
      "Epoch 38/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3672 - acc: 0.8921WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3678 - acc: 0.8922 - val_loss: 0.5209 - val_acc: 0.8315\n",
      "Epoch 39/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8930WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3649 - acc: 0.8926 - val_loss: 0.5282 - val_acc: 0.8338\n",
      "Epoch 40/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3633 - acc: 0.8922WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3636 - acc: 0.8920 - val_loss: 0.5376 - val_acc: 0.8319\n",
      "Epoch 41/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3615 - acc: 0.8940WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3616 - acc: 0.8941 - val_loss: 0.5517 - val_acc: 0.8139\n",
      "Epoch 42/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8964WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3590 - acc: 0.8965 - val_loss: 0.5257 - val_acc: 0.8259\n",
      "Epoch 43/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8949WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3575 - acc: 0.8951 - val_loss: 0.5281 - val_acc: 0.8315\n",
      "Epoch 44/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3557 - acc: 0.8971WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3549 - acc: 0.8973 - val_loss: 0.5422 - val_acc: 0.8235\n",
      "Epoch 45/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8965WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3530 - acc: 0.8966 - val_loss: 0.5396 - val_acc: 0.8329\n",
      "Epoch 46/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8981WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3522 - acc: 0.8981 - val_loss: 0.5393 - val_acc: 0.8309\n",
      "Epoch 47/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.9003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3492 - acc: 0.9001 - val_loss: 0.5504 - val_acc: 0.8163\n",
      "Epoch 48/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8996WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3479 - acc: 0.8997 - val_loss: 0.5360 - val_acc: 0.8224\n",
      "Epoch 49/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3475 - acc: 0.8997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3466 - acc: 0.8998 - val_loss: 0.5439 - val_acc: 0.8217\n",
      "Epoch 50/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.9011WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3456 - acc: 0.9009 - val_loss: 0.5410 - val_acc: 0.8300\n",
      "Epoch 51/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3419 - acc: 0.9021WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3421 - acc: 0.9021 - val_loss: 0.5376 - val_acc: 0.8281\n",
      "Epoch 52/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3418 - acc: 0.9042WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3417 - acc: 0.9042 - val_loss: 0.5448 - val_acc: 0.8268\n",
      "Epoch 53/70\n",
      "638/645 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9027WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3386 - acc: 0.9026 - val_loss: 0.5507 - val_acc: 0.8281\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3375 - acc: 0.9034WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3375 - acc: 0.9034 - val_loss: 0.5432 - val_acc: 0.8242\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3366 - acc: 0.9047WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3366 - acc: 0.9047 - val_loss: 0.5477 - val_acc: 0.8238\n",
      "Epoch 56/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.9048WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 5s 8ms/step - loss: 0.3343 - acc: 0.9049 - val_loss: 0.5680 - val_acc: 0.8271\n",
      "Epoch 57/70\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.3320 - acc: 0.9075WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3323 - acc: 0.9073 - val_loss: 0.6119 - val_acc: 0.7866\n",
      "Epoch 58/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3311 - acc: 0.9075WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3314 - acc: 0.9078 - val_loss: 0.5723 - val_acc: 0.8089\n",
      "Epoch 59/70\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.9073WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3296 - acc: 0.9075 - val_loss: 0.5645 - val_acc: 0.8163\n",
      "Epoch 60/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3290 - acc: 0.9069WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3288 - acc: 0.9069 - val_loss: 0.5543 - val_acc: 0.8278\n",
      "Epoch 61/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3266 - acc: 0.9083WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3266 - acc: 0.9083 - val_loss: 0.5676 - val_acc: 0.8239\n",
      "Epoch 62/70\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.3257 - acc: 0.9090WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3252 - acc: 0.9092 - val_loss: 0.5708 - val_acc: 0.8283\n",
      "Epoch 63/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.9100WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3232 - acc: 0.9102 - val_loss: 0.5885 - val_acc: 0.8203\n",
      "Epoch 64/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.9102WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3219 - acc: 0.9101 - val_loss: 0.6015 - val_acc: 0.7996\n",
      "Epoch 65/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3204 - acc: 0.9102WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3204 - acc: 0.9102 - val_loss: 0.5650 - val_acc: 0.8258\n",
      "Epoch 66/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.9113WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3193 - acc: 0.9114 - val_loss: 0.5658 - val_acc: 0.8258\n",
      "Epoch 67/70\n",
      "637/645 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.9118WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3188 - acc: 0.9121 - val_loss: 0.5744 - val_acc: 0.8254\n",
      "Epoch 68/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.9134WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3166 - acc: 0.9134 - val_loss: 0.5890 - val_acc: 0.8299\n",
      "Epoch 69/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.9134WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.3150 - acc: 0.9133 - val_loss: 0.5703 - val_acc: 0.8217\n",
      "Epoch 70/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.9138WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.3148 - acc: 0.9138 - val_loss: 0.5765 - val_acc: 0.8168\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.MaxPooling1D(5))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(3,activation='softmax'))\n",
    "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 3s - loss: 0.4366 - accuracy: 0.8460 - 3s/epoch - 13ms/step\n",
      "Model accuracy:  0.8460195064544678\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 3s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
    "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = ['Neutral','Negative','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['this experience has been the worst , want my money back'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['this data science article is the best ever'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['i hate youtube ads, they are annoying'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['i really loved how the technician helped me with the issue that i had'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Tokenizer saved\n"
     ]
    }
   ],
   "source": [
    "model_json = best_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "best_model.save_weights(\"model-weights.h5\")\n",
    "print(\"Model saved\")\n",
    "\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Tokenizer saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
